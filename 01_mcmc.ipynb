{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC (useing emcee package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import emcee\n",
    "from scipy.stats import distributions as D\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import matplotlib.pyplot as pl\n",
    "import scipy.optimize as op\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def histogram(y,bins=50,plot=True):\n",
    "    N,bins=np.histogram(y,bins)\n",
    "    \n",
    "    dx=bins[1]-bins[0]\n",
    "    if dx==0.0:  #  all in 1 bin!\n",
    "        val=bins[0]\n",
    "        bins=np.linspace(val-np.abs(val),val+np.abs(val),50)\n",
    "        N,bins=np.histogram(y,bins)\n",
    "    \n",
    "    dx=bins[1]-bins[0]\n",
    "    x=bins[0:-1]+(bins[1]-bins[0])/2.0\n",
    "    \n",
    "    y=N*1.0/np.sum(N)/dx\n",
    "    \n",
    "    if plot:\n",
    "        py.plot(x,y,'o-')\n",
    "        yl=py.gca().get_ylim()\n",
    "        py.gca().set_ylim([0,yl[1]])\n",
    "        xl=py.gca().get_xlim()\n",
    "        if xl[0]<=0 and xl[0]>=0:    \n",
    "            py.plot([0,0],[0,yl[1]],'k--')\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def corner(samples,labels):\n",
    "    N=len(labels)\n",
    "    from matplotlib.colors import LogNorm\n",
    "    \n",
    "    py.figure(figsize=(12,12))\n",
    "    \n",
    "    axes={}\n",
    "    for i,l1 in enumerate(labels):\n",
    "        for j,l2 in enumerate(labels):\n",
    "            if j>i:\n",
    "                continue\n",
    "                \n",
    "            ax = py.subplot2grid((N,N),(i, j))\n",
    "            axes[(i,j)]=ax\n",
    "            \n",
    "            idx_y=labels.index(l1)\n",
    "            idx_x=labels.index(l2)\n",
    "            x,y=samples[:,idx_x],samples[:,idx_y]\n",
    "            \n",
    "            if i==j:\n",
    "                # plot distributions\n",
    "                xx,yy=histogram(x,bins=200,plot=False)\n",
    "                py.plot(xx,yy,'-o',markersize=3)\n",
    "                py.gca().set_yticklabels([])\n",
    "                \n",
    "                if i==(N-1):\n",
    "                    py.xlabel(l2)\n",
    "                    [l.set_rotation(45) for l in ax.get_xticklabels()]\n",
    "                else:\n",
    "                    ax.set_xticklabels([])\n",
    "                \n",
    "            else:\n",
    "                counts,ybins,xbins,image = py.hist2d(x,y,bins=100,norm=LogNorm())\n",
    "                #py.contour(counts,extent=[xbins.min(),xbins.max(),ybins.min(),ybins.max()],linewidths=3)\n",
    "                \n",
    "                if i==(N-1):\n",
    "                    py.xlabel(l2)\n",
    "                    [l.set_rotation(45) for l in ax.get_xticklabels()]\n",
    "                else:\n",
    "                    ax.set_xticklabels([])\n",
    "                    \n",
    "                if j==0:\n",
    "                    py.ylabel(l1)\n",
    "                    [l.set_rotation(45) for l in ax.get_yticklabels()]\n",
    "                else:\n",
    "                    ax.set_yticklabels([])\n",
    "    \n",
    "    # make all the x- and y-lims the same\n",
    "    j=0\n",
    "    lims=[0]*N\n",
    "    for i in range(1,N):\n",
    "        ax=axes[(i,0)]\n",
    "        lims[i]=ax.get_ylim()\n",
    "\n",
    "        if i==N-1:\n",
    "            lims[0]=ax.get_xlim()\n",
    "    \n",
    "        \n",
    "    for i,l1 in enumerate(labels):\n",
    "        for j,l2 in enumerate(labels):\n",
    "            if j>i:\n",
    "                continue\n",
    "                \n",
    "            ax=axes[(i,j)]\n",
    "            \n",
    "            if j==i:\n",
    "                ax.set_xlim(lims[i])\n",
    "            else:\n",
    "                ax.set_ylim(lims[i])\n",
    "                ax.set_xlim(lims[j])\n",
    "\n",
    "\n",
    "greek=['alpha','beta','gamma','delta','chi','tau',\n",
    "        'sigma','lambda','epsilon','zeta','xi','theta','rho','psi']\n",
    "\n",
    "def timeit(reset=False):\n",
    "    import time\n",
    "    global _timeit_data\n",
    "    try:\n",
    "        _timeit_data\n",
    "    except NameError:\n",
    "        _timeit_data=time.time()\n",
    "        \n",
    "    if reset:\n",
    "        _timeit_data=time.time()\n",
    "\n",
    "    else:\n",
    "        return time2str(time.time()-_timeit_data)\n",
    "\n",
    "def time2str(tm):\n",
    "    \n",
    "    frac=tm-int(tm)\n",
    "    tm=int(tm)\n",
    "    \n",
    "    s=''\n",
    "    sc=tm % 60\n",
    "    tm=tm//60\n",
    "    \n",
    "    mn=tm % 60\n",
    "    tm=tm//60\n",
    "    \n",
    "    hr=tm % 24\n",
    "    tm=tm//24\n",
    "    dy=tm\n",
    "\n",
    "    if (dy>0):\n",
    "        s=s+\"%d d, \" % dy\n",
    "\n",
    "    if (hr>0):\n",
    "        s=s+\"%d h, \" % hr\n",
    "\n",
    "    if (mn>0):\n",
    "        s=s+\"%d m, \" % mn\n",
    "\n",
    "\n",
    "    s=s+\"%.2f s\" % (sc+frac)\n",
    "\n",
    "    return s\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions -- Defined for Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import scipy.optimize as op\n",
    "from scipy.special import gammaln,gamma\n",
    "def lognchoosek(N,k):\n",
    "    return gammaln(N+1)-gammaln(k+1)-gammaln((N-k)+1)\n",
    "\n",
    "def loguniformpdf(x,mn,mx):\n",
    "    if mn < x < mx:\n",
    "        return np.log(1.0/(mx-mn))\n",
    "    return -np.inf\n",
    "\n",
    "def logjeffreyspdf(x):\n",
    "    if x>0.0:\n",
    "        return -np.log(x)\n",
    "    return -np.inf\n",
    "\n",
    "def logexponpdf(x,_lambda):\n",
    "    # p(x)=l exp(l x)\n",
    "    return _lambda*x + np.log(_lambda)\n",
    "\n",
    "def logcauchypdf(x,x0,scale):\n",
    "    return -np.log(np.pi)-np.log(scale)-np.log(1 + ((x-x0)/scale)**2)\n",
    "\n",
    "def loghalfcauchypdf(x,x0,scale):\n",
    "    try:\n",
    "        N=len(x)\n",
    "    except TypeError:\n",
    "        N=1\n",
    "\n",
    "    if x<=0:\n",
    "        return -np.inf\n",
    "\n",
    "    return -np.log(np.pi)-np.log(scale)-np.log(1 + ((x-x0)/scale)**2)\n",
    "\n",
    "def loghalfnormalpdf(x,sig):\n",
    "    # x>0: 2/sqrt(2*pi*sigma^2)*exp(-x^2/2/sigma^2)\n",
    "    try:\n",
    "        N=len(x)\n",
    "    except TypeError:\n",
    "        N=1\n",
    "    if x<=0:\n",
    "        return -np.inf\n",
    "        \n",
    "    return np.log(2)-0.5*np.log(2*np.pi*sig**2)*N - np.sum(x**2/sig**2/2.0)\n",
    "\n",
    "\n",
    "def lognormalpdf(x,mn,sig,all_positive=False):\n",
    "    # 1/sqrt(2*pi*sigma^2)*exp(-x^2/2/sigma^2)\n",
    "    try:\n",
    "        N=len(x)\n",
    "        val=-0.5*np.log(2*np.pi*sig**2)*N - np.sum((x-mn)**2/sig**2/2.0)\n",
    "        if all_positive:\n",
    "            val[x<0]=-np.inf\n",
    "        # print(x,mn,val)\n",
    "        # raise ValueError(\"here\")\n",
    "        return val\n",
    "    except TypeError:\n",
    "        N=1\n",
    "        # print(x,mn)\n",
    "        # raise ValueError(\"there\")\n",
    "        val=-0.5*np.log(2*np.pi*sig**2)*N - np.sum((x-mn)**2/sig**2/2.0)\n",
    "        if all_positive and x<0:\n",
    "            val=-np.inf\n",
    "\n",
    "        return val\n",
    "    \n",
    "def logbetapdf(theta, h, N):\n",
    "    return lognchoosek(N,h)+np.log(theta)*h+np.log(1-theta)*(N-h)\n",
    "\n",
    "def loglognormalpdf(x,mn,sig):\n",
    "    if x<=0.0:\n",
    "        return -np.inf\n",
    "\n",
    "    # 1/sqrt(2*pi*sigma^2)*exp(-x^2/2/sigma^2)\n",
    "    try:\n",
    "        N=len(x)\n",
    "    except TypeError:\n",
    "        N=1\n",
    "\n",
    "    return -0.5*np.log(2*np.pi*sig**2)*N -np.log(x) - np.sum((np.log(x)-mn)**2/sig**2/2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Normal(object):\n",
    "    def __init__(self,mean=0,std=1,all_positive=False):\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.default=mean\n",
    "        self.all_positive=all_positive\n",
    "        \n",
    "    def rand(self,*args):\n",
    "\n",
    "        return np.random.randn(*args)*self.std+self.mean\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return lognormalpdf(x,self.mean,self.std,self.all_positive)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Normal(%g,%g)\" % (self.mean,self.std)\n",
    "\n",
    "class Exponential(object):\n",
    "    def __init__(self,_lambda=1):\n",
    "        self._lambda=_lambda\n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*2\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return logexponpdf(x,self._lambda)\n",
    "\n",
    "\n",
    "class Uniform(object):\n",
    "    def __init__(self,min=0,max=1):\n",
    "        self.min=min\n",
    "        self.max=max\n",
    "        self.default=(min+max)/2.0\n",
    "       \n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*(self.max-self.min)+self.min\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return loguniformpdf(x,self.min,self.max)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Uniform(%g,%g)\" % (self.min,self.max)\n",
    "\n",
    "\n",
    "class Jeffreys(object):\n",
    "    def __init__(self):\n",
    "        self.default=1.0\n",
    "        \n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*2\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return logjeffreyspdf(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Jeffreys()\"\n",
    "\n",
    "class HalfCauchy(object):\n",
    "    def __init__(self,x0=0,scale=1):\n",
    "        self.x0=x0\n",
    "        self.scale=scale\n",
    "        self.default=x0\n",
    "\n",
    "    @property\n",
    "    def D(self):\n",
    "        return D.halfcauchy(loc=self.x0,scale=self.scale) \n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*2\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return loghalfcauchypdf(x,self.x0,self.scale)\n",
    "\n",
    "\n",
    "class HalfNormal(object):\n",
    "    def __init__(self,sigma=1):\n",
    "        self.sigma=sigma\n",
    "\n",
    "    @property\n",
    "    def D(self):\n",
    "        return D.halfnorm(self.sigma)\n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*2\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return loghalfnormalpdf(x,self.sigma)\n",
    "\n",
    "\n",
    "class LogNormal(object):\n",
    "    def __init__(self,mean=0,std=1):\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.default=mean\n",
    "        \n",
    "    @property\n",
    "    def D(self):\n",
    "        return D.lognorm(self.mean,self.std)\n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.randn(*args)*self.std+self.mean\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return loglognormalpdf(x,self.mean,self.std)\n",
    "\n",
    "\n",
    "class Cauchy(object):\n",
    "    def __init__(self,x0=0,scale=1):\n",
    "        self.x0=x0\n",
    "        self.scale=scale\n",
    "        self.default=x0\n",
    "\n",
    "    @property\n",
    "    def D(self):\n",
    "        return D.cauchy(loc=self.x0,scale=self.scale) \n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)*2-1\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return logcauchypdf(x,self.x0,self.scale)\n",
    "\n",
    "\n",
    "class Beta(object):\n",
    "    def __init__(self,h=100,N=100):\n",
    "        self.h=h\n",
    "        self.N=N\n",
    "        self.default=float(h)/N\n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.rand(*args)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return logbetapdf(x,self.h,self.N)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Beta(h=%g,N=%g)\" % (self.h,self.N)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emcee functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def lnprior_function(model):\n",
    "    def _lnprior(x):\n",
    "        return model.lnprior(x)\n",
    "\n",
    "    return _lnprior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MCMCModel(object):\n",
    "    \n",
    "    def __str__(self):\n",
    "        s=\"Simulation:\\n\"\n",
    "        s+=\"\\t\"+'\\n\\t'.join(self.sim.equations().split('\\n'))\n",
    "        s+=\"\\nStats Model:\\n\"\n",
    "        for key in self.params:\n",
    "            s+=\"\\t %s = %s\" % (key,str(self.params[key]))+\"\\n\"\n",
    "        return s\n",
    "\n",
    "\n",
    "    def __init__(self,sim,**kwargs):\n",
    "        self.sim=sim\n",
    "        self.params=kwargs\n",
    "        \n",
    "        self._init_params_()\n",
    "       \n",
    "        self.nwalkers=100\n",
    "        self.burn_percentage=0.25\n",
    "        self.initial_value=None\n",
    "        self.last_pos=None\n",
    "\n",
    "        self.verbose=True\n",
    "\n",
    "    def _init_params_(self):\n",
    "        sim=self.sim\n",
    "        params=self.params\n",
    "\n",
    "        self.keys=[]\n",
    "        for key in self.params:\n",
    "            self.keys.append(key)\n",
    "            \n",
    "        self.data_components={}\n",
    "        for c in self.sim.components+self.sim.assignments:\n",
    "            if c.data:\n",
    "                key='_sigma_%s' % c.name\n",
    "                if not key in self.params:\n",
    "                    self.params[key]=Jeffreys()\n",
    "                    self.keys.append(key)\n",
    "                self.data_components[c.name]=c\n",
    "        \n",
    "        self.index={}\n",
    "        for i,key in enumerate(self.keys):\n",
    "            self.index[key]=i\n",
    "\n",
    "        self.sim_param_keys=[]\n",
    "        self.initial_value_keys=[]\n",
    "        self.sigma_keys=[]\n",
    "        self.initial_components={}\n",
    "        \n",
    "        for key in self.keys:\n",
    "            if key.startswith('_sigma_'):\n",
    "                self.sigma_keys.append(key)\n",
    "            elif key.startswith('initial_'):\n",
    "                self.initial_value_keys.append(key)\n",
    "                \n",
    "                name=key.split('initial_')[1]\n",
    "                try:\n",
    "                    _c=sim.get_component(name)\n",
    "                except IndexError:\n",
    "                    raise ValueError(\"%s is a bad initial variable because %s is not a variable in the dynamical model.\" % (key,name))\n",
    "                self.initial_components[key]=_c\n",
    "\n",
    "            else:\n",
    "                self.sim_param_keys.append(key)\n",
    "                if not key in sim.original_params:\n",
    "                    raise ValueError(\"%s is not a parameter in the dynamical model.  Parameters are %s\" % (key,str(sim.original_params)))\n",
    " \n",
    "\n",
    "    # Define the probability function as likelihood * prior.\n",
    "    def lnprior(self,theta):        \n",
    "        value=0.0\n",
    "        for i,key in enumerate(self.keys):\n",
    "            value+=self.params[key](theta[i])\n",
    "                \n",
    "        return value\n",
    "\n",
    "    def lnlike(self,theta):\n",
    "        \n",
    "        # set the parameters\n",
    "        params={}\n",
    "        for key in self.sim_param_keys:\n",
    "            params[key]=theta[self.index[key]]\n",
    "        self.sim.params(**params)\n",
    "        \n",
    "        # set the initial values\n",
    "        for key in self.initial_value_keys:\n",
    "            self.initial_components[key].initial_value=theta[self.index[key]]\n",
    "        \n",
    "            \n",
    "        # run the sim\n",
    "        self.sim.run_fast()\n",
    "        \n",
    "        # compare with data\n",
    "        \n",
    "        value=0.0\n",
    "        for name in self.data_components:\n",
    "            key='_sigma_%s' % name\n",
    "            _c=self.data_components[name]\n",
    "            sigma=theta[self.index[key]]\n",
    "            \n",
    "            t=np.array(_c.data['t']).ravel()\n",
    "            y=np.array(_c.data['value']).ravel()\n",
    "            y_fit=self.sim.interpolate(t,name)\n",
    "\n",
    "            if any(np.isnan(y_fit)):\n",
    "                return -np.inf\n",
    "\n",
    "            if any(abs(y_fit)>1e100):\n",
    "                return -np.inf\n",
    "                \n",
    "\n",
    "            value+=lognormalpdf(y,y_fit,sigma)\n",
    "            # print(sigma)\n",
    "            # print(y.__repr__())\n",
    "            # print(y_fit.__repr__())\n",
    "            # print(theta)\n",
    "            # raise ValueError\n",
    "            \n",
    "        return value\n",
    "    \n",
    "    def assign_sim_values(self,theta):\n",
    "        # set the parameters\n",
    "        params={}\n",
    "        for key in self.sim_param_keys:\n",
    "            params[key]=theta[self.index[key]]\n",
    "        self.sim.params(**params)\n",
    "        \n",
    "        # set the initial values\n",
    "        for key in self.initial_value_keys:\n",
    "            self.initial_components[key].initial_value=theta[self.index[key]]\n",
    "        \n",
    "        \n",
    "    def lnlike_lownoise(self,theta):\n",
    "        \n",
    "        self.assign_sim_values(theta)        \n",
    "        \n",
    "        # run the sim\n",
    "        self.sim.run_fast()\n",
    "        \n",
    "        # compare with data\n",
    "        \n",
    "        value=0.0\n",
    "        for name in self.data_components:\n",
    "            key='_sigma_%s' % name\n",
    "            _c=self.data_components[name]\n",
    "            sigma=theta[self.index[key]]\n",
    "            \n",
    "            t=_c.data['t'].ravel()\n",
    "            y=_c.data['value'].ravel()\n",
    "            y_fit=self.sim.interpolate(t,name)\n",
    "            value+=lognormalpdf(y,y_fit,1.0)  # replace sigma with 1.0\n",
    "            \n",
    "        return value\n",
    "\n",
    "    def lnprob(self,theta):\n",
    "        lp = self.lnprior(theta)\n",
    "        if np.isnan(lp):\n",
    "            return -np.inf\n",
    "\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "\n",
    "        lnl=self.lnlike(theta)  \n",
    "        if np.isnan(lnl):\n",
    "            return -np.inf\n",
    "            \n",
    "        return lp + lnl      \n",
    "\n",
    "    def __call__(self,theta):\n",
    "        return self.lnprob(theta)\n",
    "    \n",
    "    def set_initial_values(self,method='prior',*args,**kwargs):\n",
    "        if isinstance(method,(list,np.ndarray)):\n",
    "            ndim=len(self.params)\n",
    "            vals=method\n",
    "            self.last_pos=array(vals)\n",
    "            assert self.last_pos.shape==(self.nwalkers,ndim)\n",
    "        elif method=='sim':\n",
    "            self.initial_value=np.ones(len(self.params))\n",
    "            \n",
    "            for key in self.sim_param_keys:\n",
    "                self.initial_value[self.index[key]]=self.sim.myparams[key]\n",
    "            \n",
    "            for key in self.initial_value_keys:\n",
    "                _c=self.initial_components[key]\n",
    "                self.initial_value[self.index[key]]=_c.initial_value\n",
    "            self.last_pos=emcee.utils.sample_ball(self.initial_value, 0.05*self.initial_value+1e-4, size=self.nwalkers)\n",
    "        elif method=='samples':\n",
    "            lower,upper=np.percentile(self.samples, [16,84],axis=0)            \n",
    "            subsamples=self.samples[((self.samples>=lower) & (self.samples<=upper)).all(axis=1),:]\n",
    "            idx=np.random.randint(subsamples.shape[0],size=self.last_pos.shape[0])\n",
    "            self.last_pos=subsamples[idx,:]            \n",
    "        elif method=='prior':\n",
    "            ndim=len(self.params)\n",
    "            try:\n",
    "                N=args[0]\n",
    "            except IndexError:\n",
    "                N=300\n",
    "\n",
    "            pos=np.zeros((self.nwalkers,ndim))\n",
    "            for i,key in enumerate(self.keys):\n",
    "                pos[:,i]=self.params[key].rand(100)\n",
    "\n",
    "            \n",
    "            self.sampler = emcee.EnsembleSampler(self.nwalkers, ndim, \n",
    "                    lnprior_function(self))\n",
    "\n",
    "            if self.verbose:\n",
    "                timeit(reset=True)\n",
    "                print(\"Sampling Prior...\")\n",
    "\n",
    "            self.sampler.run_mcmc(pos, N,**kwargs)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Done.\")\n",
    "                print(timeit())\n",
    "\n",
    "            # assign the median back into the simulation values\n",
    "            self.burn()\n",
    "            self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "\n",
    "            self.last_pos=self.sampler.chain[:,-1,:]\n",
    "\n",
    "        elif method=='maximum likelihood':\n",
    "            self.initial_value=zeros(len(self.params))\n",
    "            \n",
    "            for key in self.sim_param_keys:\n",
    "                self.initial_value[self.index[key]]=self.sim.myparams[key]\n",
    "            \n",
    "            for key in self.initial_value_keys:\n",
    "                _c=self.initial_components[key]\n",
    "                self.initial_value[self.index[key]]=_c.initial_value\n",
    "            \n",
    "            for key in self.sigma_keys:\n",
    "                self.initial_value[self.index[key]]=1.0\n",
    "            \n",
    "            chi2 = lambda *args: -2 * self.lnlike_lownoise(*args)\n",
    "            result = op.minimize(chi2, self.initial_value)\n",
    "            vals=result['x']\n",
    "            self.initial_value=array(vals)\n",
    "            self.last_pos=emcee.utils.sample_ball(self.initial_value, 0.05*self.initial_value+1e-4, size=self.nwalkers)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: %s\" % method)\n",
    "\n",
    "                    \n",
    "    \n",
    "    def burn(self,burn_percentage=None):\n",
    "        if not burn_percentage is None:\n",
    "            self.burn_percentage=burn_percentage\n",
    "            \n",
    "        burnin = int(self.sampler.chain.shape[1]*self.burn_percentage)  # burn 25 percent\n",
    "        ndim=len(self.params)\n",
    "        self.samples = self.sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "        \n",
    "    \n",
    "    def run_mcmc(self,N,repeat=1,**kwargs):\n",
    "        \n",
    "        ndim=len(self.params)\n",
    "        \n",
    "        if self.last_pos is None:\n",
    "            self.set_initial_values()\n",
    "        \n",
    "        self.real_initial_value=self.last_pos.copy()\n",
    "        \n",
    "\n",
    "        for i in range(repeat):\n",
    "            self.sampler = emcee.EnsembleSampler(self.nwalkers, ndim, self,)\n",
    "\n",
    "            if self.verbose:\n",
    "                timeit(reset=True)\n",
    "                print(\"Running MCMC %d/%d...\" % (i+1,repeat))\n",
    "\n",
    "            self.sampler.run_mcmc(self.last_pos, N,**kwargs)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Done.\")\n",
    "                print(timeit())\n",
    "\n",
    "        \n",
    "            # assign the median back into the simulation values\n",
    "            self.burn()\n",
    "            self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "            theta=self.median_values\n",
    "\n",
    "        \n",
    "\n",
    "            self.assign_sim_values(theta)\n",
    "            self.initial_value=theta\n",
    "            self.last_pos=self.sampler.chain[:,-1,:]\n",
    "\n",
    "\n",
    "            if repeat>1:\n",
    "                self.set_initial_values('samples')  # reset using the 16-84 percentile values from the samples\n",
    "\n",
    "        # calculate BIC\n",
    "        k=len(theta)\n",
    "        N=0\n",
    "        for name in self.data_components:\n",
    "            key='_sigma_%s' % name\n",
    "            _c=self.data_components[name]\n",
    "            sigma=theta[self.index[key]]\n",
    "            \n",
    "            t=_c.data['t']\n",
    "            y=_c.data['value']\n",
    "\n",
    "            N+=len(y)\n",
    "\n",
    "\n",
    "        # lower BIC = good\n",
    "        \n",
    "        self.BIC=k * np.log(N)-2.0*self.lnlike(theta)\n",
    "\n",
    "        # ΔBIC    Evidence against higher BIC\n",
    "        # 0 to 2  Not worth more than a bare mention\n",
    "        # 2 to 6  Positive\n",
    "        # 6 to 10 Strong\n",
    "        # >10 Very Strong\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def WAIC(self):\n",
    "        # WAIC\n",
    "        # from https://github.com/pymc-devs/pymc3/blob/02f0b7f9a487cf18e9a48b754b54c2a99cf9fba8/pymc3/stats.py\n",
    "        # We get three different measurements:\n",
    "        # waic: widely available information criterion\n",
    "        # waic_se: standard error of waic\n",
    "        # p_waic: effective number parameters\n",
    "\n",
    "        log_py=np.atleast_2d(array([self.lnprob(theta) \n",
    "                                        for theta in self.samples])).T\n",
    "        lppd_i = logsumexp(log_py, axis=0, b=1.0 / len(log_py))\n",
    "        vars_lpd = np.var(log_py, axis=0)\n",
    "        warn_mg = 0\n",
    "        if np.any(vars_lpd > 0.4):\n",
    "            warnings.warn(\"\"\"For one or more samples the posterior variance of the\n",
    "            log predictive densities exceeds 0.4. This could be indication of\n",
    "            WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
    "            \"\"\")\n",
    "            warn_mg = 1\n",
    "\n",
    "        waic_i = - 2 * (lppd_i - vars_lpd)\n",
    "        waic = np.sum(waic_i)\n",
    "        waic_se = np.sqrt(len(waic_i) * np.var(waic_i))\n",
    "        p_waic = np.sum(vars_lpd)            \n",
    "\n",
    "        self.waic={'waic': waic,\n",
    "                   'waic_se':waic_se,\n",
    "                   'p_waic':p_waic,\n",
    "        }\n",
    "\n",
    "        return waic,waic_se,p_waic\n",
    "\n",
    "    def plot_chains(self,*args,**kwargs):\n",
    "        pl.clf()\n",
    "        \n",
    "        if not args:\n",
    "            args=self.keys\n",
    "        \n",
    "        \n",
    "        fig, axes = pl.subplots(len(self.params), 1, sharex=True, figsize=(8, 5*len(args)))\n",
    "\n",
    "        labels=[]\n",
    "        for ax,key in zip(axes,args):\n",
    "            i=self.index[key]\n",
    "            sample=self.sampler.chain[:, :, i].T\n",
    "\n",
    "            if key.startswith('_sigma_'):\n",
    "                name=key.split('_sigma_')[1]\n",
    "                label=r'$\\sigma_{%s}$' % name\n",
    "            else:\n",
    "                namestr=key\n",
    "                for g in greek:\n",
    "                    if key.startswith(g):\n",
    "                        namestr=r'\\%s' % key\n",
    "\n",
    "                label='$%s$' % namestr\n",
    "\n",
    "            labels.append(label)\n",
    "            ax.plot(sample, color=\"k\", alpha=0.2,**kwargs)\n",
    "            ax.set_ylabel(label)\n",
    "\n",
    "            \n",
    "    def triangle_plot(self,*args,**kwargs):\n",
    "        \n",
    "        if not args:\n",
    "            args=self.keys\n",
    "            \n",
    "        assert len(args)>1\n",
    "        \n",
    "        labels=[]\n",
    "        idx=[]\n",
    "        for key in args:\n",
    "            if key.startswith('_sigma_'):\n",
    "                name=key.split('_sigma_')[1]\n",
    "                label=r'$\\sigma_{%s}$' % name\n",
    "            else:\n",
    "                namestr=key\n",
    "                for g in greek:\n",
    "                    if key.startswith(g):\n",
    "                        namestr=r'\\%s' % key\n",
    "\n",
    "                label='$%s$' % namestr\n",
    "\n",
    "            labels.append(label)\n",
    "            idx.append(self.index[key])\n",
    "        \n",
    "        fig = corner(self.samples[:,idx], labels=labels)\n",
    "        \n",
    "    def plot_distributions(self,*args,**kwargs):\n",
    "        if not args and not kwargs:\n",
    "            keys=list(self.keys)\n",
    "        else:\n",
    "            keys=list(args)\n",
    "\n",
    "        keys=keys+list(kwargs.keys())\n",
    "        \n",
    "        for key in keys:\n",
    "\n",
    "            if type(key)==str:\n",
    "\n",
    "                if key.startswith('_sigma_'):\n",
    "                    name=key.split('_sigma_')[1]\n",
    "                    label=r'\\sigma_{%s}' % name\n",
    "                else:\n",
    "                    namestr=key\n",
    "                    for g in greek:\n",
    "                        if key.startswith(g):\n",
    "                            namestr=r'\\%s' % key\n",
    "\n",
    "                    label='%s' % namestr\n",
    "                if key in kwargs:\n",
    "                    values=kwargs[key]\n",
    "                else:\n",
    "                    i=self.index[key]\n",
    "                    values=self.samples[:,i]\n",
    "            else:\n",
    "                values=key\n",
    "                label='value'\n",
    "\n",
    "\n",
    "            py.figure(figsize=(12,4))\n",
    "            result=histogram(values,bins=200)\n",
    "            xlim=pl.gca().get_xlim()\n",
    "            x=py.linspace(xlim[0],xlim[1],500)\n",
    "            y=D.norm.pdf(x,np.median(values),np.std(values))\n",
    "            py.plot(x,y,'-')\n",
    "\n",
    "            v=np.percentile(values, [2.5, 50, 97.5],axis=0)\n",
    "\n",
    "            if v[1]<.005 or (v[2]-v[1])<0.005 or (v[1]-v[0])<0.005:\n",
    "                py.title(r'$\\hat{%s}^{97.5}_{2.5}=%.3g^{+%.3g}_{-%.3g}$' % (label,v[1],(v[2]-v[1]),(v[1]-v[0])))\n",
    "            else:\n",
    "                py.title(r'$\\hat{%s}^{97.5}_{2.5}=%.3f^{+%.3f}_{-%.3f}$' % (label,v[1],(v[2]-v[1]),(v[1]-v[0])))\n",
    "            py.ylabel(r'$p(%s|{\\rm data})$' % label)\n",
    "\n",
    "    def eval(self,S):\n",
    "        for i,key in enumerate(self.keys):\n",
    "            exec('%s=self.samples[:,i]' % key)\n",
    "        result=eval(S)\n",
    "        return result\n",
    "\n",
    "\n",
    "    \n",
    "    def get_distribution(self,key,bins=200):\n",
    "            \n",
    "        i=self.index[key]\n",
    "        x,y=histogram(self.samples[:,i],bins=bins,plot=False)\n",
    "        \n",
    "        return x,y\n",
    "        \n",
    "    def plot_many(self,t_min,t_max,params,N=500,alpha=0.05):\n",
    "        sim=self.sim\n",
    "        if isinstance(params,str):\n",
    "            params=[params]\n",
    "        \n",
    "        sim.noplots=True  # turn off the simulation plots\n",
    "        for i in range(N):\n",
    "            self.draw()\n",
    "            sim.run(t_min,t_max)\n",
    "            for num,p in enumerate(params):\n",
    "                t=sim.t\n",
    "                v=sim[p]\n",
    "                py.figure(num+1)\n",
    "                py.plot(t,v,'g-',alpha=alpha)\n",
    "        sim.noplots=False  # gotta love a double-negative\n",
    "        for num,p in enumerate(params):\n",
    "            py.figure(num+1)\n",
    "            c=sim.get_component(p)\n",
    "            py.ylabel(c.label)\n",
    "            py.xlabel('time')\n",
    "            if not c.data:\n",
    "                continue\n",
    "            t=c.data['t']\n",
    "            v=c.data['value']\n",
    "            py.plot(t,v,'bo')  \n",
    "\n",
    "\n",
    "    def percentiles(self,p=[16, 50, 84]):\n",
    "        result={}\n",
    "        for i,key in enumerate(self.keys):\n",
    "            result[key]=np.percentile(self.samples[:,i], p,axis=0)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def get_samples(self,*args):\n",
    "        result=[]\n",
    "\n",
    "        if not args:\n",
    "            args=self.keys\n",
    "\n",
    "        for a in args:\n",
    "            i=self.keys.index(a)\n",
    "            result.append(self.samples[:,i])\n",
    "            \n",
    "        if len(result)==1:\n",
    "            return result[0]\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    def best_estimates(self):\n",
    "        self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "        theta=self.median_values\n",
    "        \n",
    "        self.assign_sim_values(theta)\n",
    "        return self.percentiles()\n",
    "        \n",
    "    def draw(self):\n",
    "        s=np.random.randint(self.samples.shape[0])\n",
    "        theta=self.samples[s,:]\n",
    "        self.assign_sim_values(theta)\n",
    "        return theta\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MCMCModelReg(MCMCModel):\n",
    "\n",
    "    def __init__(self,sim,verbose=True,**kwargs):\n",
    "        super().__init__(sim, **kwargs)\n",
    "        self.apply_regression(verbose)\n",
    "        self._init_params_()\n",
    "        \n",
    "    def apply_regression(self,verbose=True):\n",
    "        model=self\n",
    "        sim=self.sim\n",
    "\n",
    "        # make a common time variable\n",
    "        from operator import or_\n",
    "        from functools import reduce\n",
    "        t=np.array(sorted(reduce(or_, [set(c.data['t']) for c in sim.components if c.data])))    \n",
    "\n",
    "        from numpy import gradient,interp    \n",
    "        from statsmodels.formula.api import ols\n",
    "\n",
    "        data={'t':t}\n",
    "        for c in sim.components:\n",
    "            if not c.data:\n",
    "                continue\n",
    "\n",
    "            data[c.name]=interp(t,c.data['t'],c.data['value'])\n",
    "            data['d%s_dt' % c.name]=gradient(data[c.name],t)            \n",
    "\n",
    "        if verbose:\n",
    "            print(data)\n",
    "\n",
    "        model_results=[]\n",
    "        for c in sim.components:\n",
    "            if not c.data:\n",
    "                continue\n",
    "\n",
    "            eqn=c.diffstr\n",
    "\n",
    "            if '-' in eqn:\n",
    "                raise NotImplementedError(\"Equation: '%s'\" % eqn)\n",
    "\n",
    "            parts=eqn.split('+')\n",
    "            param_names=[p.split('*')[0].strip() for p in parts]\n",
    "            rest=['*'.join(p.split('*')[1:]) for p in parts]\n",
    "\n",
    "            regeqn=\"d%s_dt ~ \" % c.name\n",
    "            found_intercept=False\n",
    "            terms=[]\n",
    "            for r in rest:\n",
    "                if not r:  # intercept\n",
    "                    regeqn+=\" +1 \"\n",
    "                    terms.append('Intercept')\n",
    "                    found_intercept=True\n",
    "                else:\n",
    "                    term=\"I(%s)\" % r.strip().replace(' ','')\n",
    "                    terms.append(term)\n",
    "                    regeqn+=\" +%s \" % term\n",
    "\n",
    "            if not found_intercept:\n",
    "                regeqn+=\" -1 \"\n",
    "\n",
    "            if verbose:\n",
    "                print(\"regeqn: \",regeqn)\n",
    "\n",
    "            model_E = ols(regeqn,data)\n",
    "            result_E = model_E.fit()\n",
    "\n",
    "            parse_info={'terms':terms,'param_names':param_names}\n",
    "            model_results.append((parse_info,model_E,result_E))\n",
    "            if verbose:\n",
    "                print(result_E.summary())\n",
    "\n",
    "            translation={}\n",
    "            for name in model_E.exog_names:\n",
    "                idx=terms.index(name.strip().replace(' ',''))\n",
    "                translation[name]=param_names[idx]\n",
    "            if verbose:\n",
    "                print(translation)\n",
    "\n",
    "\n",
    "            for t in translation:\n",
    "                p,b=result_E.params[t],result_E.bse[t]\n",
    "                mn=p\n",
    "                sd=b*0.5\n",
    "                model.params[translation[t]]=Normal(mn,sd)\n",
    "                sim.myparams[translation[t]]=mn\n",
    "                sim.original_params[translation[t]]=mn\n",
    "\n",
    "        if verbose:\n",
    "            print(model)\n",
    "\n",
    "        self.model_results=model_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
